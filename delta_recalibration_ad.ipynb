{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_global_perplexities(base_dir, group, epochs, transcription_type, batch_size):\n",
    "    patient_dirs = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "    patient_dirs.sort()\n",
    "    \n",
    "    dict_ppl = {e: [] for e in epochs}\n",
    "\n",
    "    for patient_dir in patient_dirs:\n",
    "        patient_path = os.path.join(base_dir, patient_dir)\n",
    "        for e in epochs:\n",
    "            file_name = f\"{patient_dir}_modello_{group}_{transcription_type}_{batch_size}b_{e}ep_global_ppl_score.txt\"\n",
    "            try:\n",
    "                with open(os.path.join(patient_path, file_name), 'r') as f:\n",
    "                    perplexity = float(f.read().strip())\n",
    "                    dict_ppl[e].append(perplexity)\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "\n",
    "    return dict_ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_plot_global(w, epochs, fold, dataset, transcription_type, batch_size, disease_class, control_class):\n",
    "    base_dir = f\"{dataset}/{dataset}_fold_{fold}/{dataset}_fold_{fold}_w{w}_l0/dev/{transcription_type}\"\n",
    "\n",
    "    dict_ad = load_global_perplexities(base_dir, disease_class, epochs, transcription_type, batch_size)\n",
    "    dict_cn = load_global_perplexities(base_dir, control_class, epochs, transcription_type, batch_size)\n",
    "    \n",
    "\n",
    "    mean_ad = [np.nanmean(dict_ad[e]) for e in epochs]\n",
    "    mean_cn = [np.nanmean(dict_cn[e]) for e in epochs]\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, mean_ad, marker='o', label='AD Model on all dev patients', color='red')\n",
    "    plt.plot(epochs, mean_cn, marker='o', label='CN Model on all dev patients', color='blue')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Perplexity')\n",
    "    #plt.title(f'Global Perplexity Evolution - Dev. Set - Fold {fold} - Window {w}')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.xticks(ticks=[5,10,15])  # ensures all epoch numbers are displayed\n",
    "    plt.ylim(10,50)\n",
    "\n",
    "    \n",
    "    plt.legend()\n",
    "    for means, color in zip([mean_ad, mean_cn], ['red', 'blue']):\n",
    "        for x, y in zip(epochs, means):\n",
    "            plt.text(x, y + 0.02, f\"{y:.2f}\", ha='center', color=color)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # check if the folder fig/{dataset}/ exists, if not create it\n",
    "    if not os.path.exists(f\"fig/{dataset}\"):\n",
    "        os.makedirs(f\"fig/{dataset}\")\n",
    "        \n",
    "    # Save the plot        \n",
    "    plot_name = f\"fig/{dataset}/perplexity_evolution_dev_set_fold_{fold}_w{w}\"\n",
    "    plt.savefig(f\"{plot_name}.png\")\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "    # Matrice differenze (AD - CN)\n",
    "    matrix = np.empty((len(epochs), len(epochs)))\n",
    "    for i, ad_epoch in enumerate(epochs):\n",
    "        for j, cn_epoch in enumerate(epochs):\n",
    "            ad_vals = dict_ad[ad_epoch]\n",
    "            cn_vals = dict_cn[cn_epoch]\n",
    "            if ad_vals and cn_vals:  # check that both lists are not empty\n",
    "                matrix[i, j] = np.mean(ad_vals) - np.mean(cn_vals)\n",
    "            else:\n",
    "                matrix[i, j] = np.nan\n",
    "                \n",
    "    # check if the folder {dataset}/{dataset}_matrices/ exists, if not create it\n",
    "    if not os.path.exists(f\"{dataset}/{dataset}_matrices\"):\n",
    "        os.makedirs(f\"{dataset}/{dataset}_matrices\")\n",
    "    \n",
    "    #¬†Save the matrix to a CSV file\n",
    "    matrix_df = pd.DataFrame(matrix, index=epochs, columns=epochs)\n",
    "    matrix_df.to_csv(f\"{dataset}/{dataset}_matrices/matrix_diff_ad_cn_fold_{fold}_w{w}.csv\", index=True, header=True)\n",
    "\n",
    "    # Save the mean_ad and mean_cn to CSV files\n",
    "    mean_ad_df = pd.DataFrame(mean_ad, index=epochs, columns=['Mean AD'])\n",
    "    mean_ad_df.to_csv(f\"{dataset}/{dataset}_matrices/mean_ad_fold_{fold}_w{w}.csv\", index=True, header=True)\n",
    "    mean_cn_df = pd.DataFrame(mean_cn, index=epochs, columns=['Mean CN'])\n",
    "    mean_cn_df.to_csv(f\"{dataset}/{dataset}_matrices/mean_cn_fold_{fold}_w{w}.csv\", index=True, header=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_test(base_dir_test, epochs, fold, w, dataset, transcription_type, batch_size, disease_class, control_class):\n",
    "    dict_ad = load_global_perplexities(base_dir_test, disease_class, epochs, transcription_type, batch_size)\n",
    "    dict_cn = load_global_perplexities(base_dir_test, control_class, epochs, transcription_type, batch_size)\n",
    "    \n",
    "    label_df = pd.read_csv(f\"{dataset}/labels.csv\", sep=';')\n",
    "    labels = dict(zip(label_df['patient_id'], label_df['label']))\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    # Loop over all epoch pairs\n",
    "    for i, ad_epoch in enumerate(epochs):\n",
    "        for j, cn_epoch in enumerate(epochs):\n",
    "            errors = 0\n",
    "            total = 0\n",
    "            predictions = []\n",
    "            count_ad_pred_cn = 0\n",
    "            count_cn_pred_ad = 0\n",
    "            count_ad_pred_ad = 0\n",
    "            count_cn_pred_cn = 0\n",
    "\n",
    "            for subj_idx, subj_id in enumerate(dict_ad[ad_epoch]):\n",
    "                try:\n",
    "                    subj_label = labels[list(label_df['patient_id'])[subj_idx]]\n",
    "                    value = list(label_df['patient_id'])[subj_idx]  # subject ID\n",
    "                except IndexError:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    ppl_ad = dict_ad[ad_epoch][subj_idx]\n",
    "                    ppl_cn = dict_cn[cn_epoch][subj_idx]\n",
    "                except IndexError:\n",
    "                    continue\n",
    "\n",
    "                diff = ppl_ad - ppl_cn\n",
    "                if diff > 0:\n",
    "                    pred = 'Control' if disease_class == 'ad' else 'human'\n",
    "                else:\n",
    "                    pred = 'Non Healthy' if control_class == 'cn' else 'machine'\n",
    "\n",
    "\n",
    "                predictions.append((subj_idx, subj_label, pred))\n",
    "                \n",
    "                if pred != subj_label:\n",
    "                    errors += 1\n",
    "                    if pred == 'Control':\n",
    "                        count_ad_pred_cn += 1\n",
    "                    else:\n",
    "                        count_cn_pred_ad += 1\n",
    "                else:\n",
    "                    if pred == 'Control':\n",
    "                        count_cn_pred_cn += 1\n",
    "                    else:\n",
    "                        count_ad_pred_ad += 1\n",
    "                    \n",
    "                total += 1\n",
    "\n",
    "            # accuracy\n",
    "            acc = 1 - (errors / total) if total else 0\n",
    "\n",
    "       \n",
    "            #¬†F1 score calculation\n",
    "            # precision = tp / (tp + fp)\n",
    "            # recall = tp / (tp + fn)\n",
    "            \n",
    "            f1_per_class = {}\n",
    "            precision_ad = count_ad_pred_ad / (count_ad_pred_ad + count_cn_pred_ad) if (count_ad_pred_ad + count_cn_pred_ad) > 0 else 0\n",
    "            recall_ad = count_ad_pred_ad / (count_ad_pred_ad + count_ad_pred_cn) if (count_ad_pred_ad + count_ad_pred_cn) > 0 else 0\n",
    "            f1_per_class[disease_class] = 2 * (precision_ad * recall_ad) / (precision_ad + recall_ad) if (precision_ad + recall_ad) > 0 else 0\n",
    "            \n",
    "            precision_cn = count_cn_pred_cn / (count_cn_pred_cn + count_ad_pred_cn) if (count_cn_pred_cn + count_ad_pred_cn) > 0 else 0\n",
    "            recall_cn = count_cn_pred_cn / (count_cn_pred_cn + count_cn_pred_ad) if (count_cn_pred_cn + count_cn_pred_ad) > 0 else 0\n",
    "            f1_per_class[control_class] = 2 * (precision_cn * recall_cn) / (precision_cn + recall_cn) if (precision_cn + recall_cn) > 0 else 0\n",
    "\n",
    "            macro_f1 = (f1_per_class[disease_class] + f1_per_class[control_class]) / 2\n",
    "\n",
    "            # prepare results entry\n",
    "            result_entry = {\n",
    "                'ad_epoch': ad_epoch,\n",
    "                'cn_epoch': cn_epoch,\n",
    "                'errors': errors,\n",
    "                'accuracy': acc,\n",
    "                'ad_predicted_cn': count_ad_pred_cn,\n",
    "                'cn_predicted_ad': count_cn_pred_ad,\n",
    "                f'f1_{disease_class}': f1_per_class[disease_class],\n",
    "                f'f1_{control_class}': f1_per_class[control_class],\n",
    "                'macro_f1': macro_f1\n",
    "            }\n",
    "\n",
    "            results.append(result_entry)\n",
    "    # check if the folder {dataset}/{dataset}_results/ exists, if not create it\n",
    "    if not os.path.exists(f\"{dataset}/{dataset}_results\"):\n",
    "        os.makedirs(f\"{dataset}/{dataset}_results\")\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(f\"{dataset}/{dataset}_results/classification_results_fold_{fold}_w{w}.csv\", index=False)\n",
    "    print(f\"\\nClassification results for Fold {fold} - Window {w}:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_correlation_ppl_valid_classific_test_not_overfitting(epochs, fold, w, dataset):\n",
    "    try:\n",
    "        # Load results\n",
    "        results_df = pd.read_csv(f\"{dataset}/{dataset}_results/classification_results_fold_{fold}_w{w}.csv\")\n",
    "\n",
    "        # Load matrix as NumPy array\n",
    "        matrix_df = pd.read_csv(f\"{dataset}/{dataset}_matrices/matrix_diff_ad_cn_fold_{fold}_w{w}.csv\", index_col=0)\n",
    "        matrix = matrix_df.values  # convert to NumPy array\n",
    "        \n",
    "        mean_ad_df = pd.read_csv(f\"{dataset}/{dataset}_matrices/mean_ad_fold_{fold}_w{w}.csv\", index_col=0)\n",
    "        mean_cn_df = pd.read_csv(f\"{dataset}/{dataset}_matrices/mean_cn_fold_{fold}_w{w}.csv\", index_col=0)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load data for fold {fold}, w {w}: {e}\")\n",
    "        return\n",
    "\n",
    "    min_ad_epoch_idx = mean_ad_df.values.argmin()\n",
    "    min_cn_epoch_idx = mean_cn_df.values.argmin()\n",
    "    min_ad_epoch_val = epochs[min_ad_epoch_idx]\n",
    "    min_cn_epoch_val = epochs[min_cn_epoch_idx]\n",
    "\n",
    "\n",
    "    # Filter using actual epoch values\n",
    "    results_df = results_df[\n",
    "        (results_df['ad_epoch'] <= min_ad_epoch_val) & (results_df['cn_epoch'] <= min_cn_epoch_val)\n",
    "    ]\n",
    "\n",
    "    # Compute deltas *after* filtering\n",
    "    deltas = []\n",
    "    for _, row in results_df.iterrows():\n",
    "        try:\n",
    "            i = epochs.index(row['ad_epoch'])\n",
    "            j = epochs.index(row['cn_epoch'])\n",
    "            deltas.append(abs(matrix[i, j]))\n",
    "        except Exception:\n",
    "            deltas.append(np.nan)\n",
    "\n",
    "    results_df['delta'] = deltas\n",
    "    results_df.dropna(subset=['accuracy', 'delta'], inplace=True)\n",
    "\n",
    "    if len(results_df) < 2:\n",
    "        print(f\"‚ö†Ô∏è Not enough valid data to compute correlation for fold={fold}, w={w}\")\n",
    "        return\n",
    "\n",
    "    # Correlation computations\n",
    "    pearson_corr, pearson_p = pearsonr(results_df['delta'], results_df['accuracy'])\n",
    "    spearman_corr, spearman_p = spearmanr(results_df['delta'], results_df['accuracy'])\n",
    "\n",
    "        \n",
    "    print(f\"üìä Pearson correlation: {pearson_corr:.4f} (p={pearson_p:.4e})\")\n",
    "    print(f\"üìà Spearman correlation: {spearman_corr:.4f} (p={spearman_p:.4e})\")\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(results_df['delta'], results_df['accuracy'], alpha=0.7)\n",
    "\n",
    "    # Regression line\n",
    "    z = np.polyfit(results_df['delta'], results_df['accuracy'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_vals = np.sort(results_df['delta'])\n",
    "    plt.plot(x_vals, p(x_vals), \"r--\")\n",
    "\n",
    "    # Text annotation\n",
    "    plt.text(\n",
    "        0.05, 0.05,\n",
    "        f\"Pearson r: {pearson_corr:.4f} (p={pearson_p:.4e})\\n\"\n",
    "        f\"Spearman r: {spearman_corr:.4f} (p={spearman_p:.4e})\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        bbox=dict(facecolor='white', alpha=0.8),\n",
    "        fontsize=20\n",
    "    )\n",
    "\n",
    "    plt.yticks([0,0.25,0.5,0.75,1])\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.xticks(fontsize=20)\n",
    "\n",
    "    \n",
    "    plt.xlim(left=0)\n",
    "    max_val = results_df['delta'].max()\n",
    "    plt.xticks(np.arange(0, max_val + 2, 5))\n",
    "    \n",
    "    plt.grid(True)\n",
    "    #plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot\n",
    "    plot_path = f\"fig/{dataset}/not_overfitting_accuracy_vs_delta_fold_{fold}_w{w}.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    print(f\"‚úÖ Plot saved: {plot_path}\")\n",
    "\n",
    "\n",
    "def print_correlation_ppl_valid_classific_test(epochs, fold, w, dataset):\n",
    "    try:\n",
    "        # Load results\n",
    "        results_df = pd.read_csv(f\"{dataset}/{dataset}_results/classification_results_fold_{fold}_w{w}.csv\")\n",
    "\n",
    "        # Load matrix as NumPy array\n",
    "        matrix_df = pd.read_csv(f\"{dataset}/{dataset}_matrices/matrix_diff_ad_cn_fold_{fold}_w{w}.csv\", index_col=0)\n",
    "        matrix = matrix_df.values  # convert to NumPy array\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load data for fold {fold}, w {w}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Compute deltas using index lookup\n",
    "    deltas = []\n",
    "    for _, row in results_df.iterrows():\n",
    "        try:\n",
    "            i = epochs.index(row['ad_epoch'])\n",
    "            j = epochs.index(row['cn_epoch'])\n",
    "            deltas.append(abs(matrix[i, j]))\n",
    "        except Exception:\n",
    "            deltas.append(np.nan)\n",
    "\n",
    "    results_df['delta'] = deltas\n",
    "    results_df.dropna(subset=['accuracy', 'delta'], inplace=True)\n",
    "\n",
    "    if len(results_df) < 2:\n",
    "        print(f\"‚ö†Ô∏è Not enough valid data to compute correlation for fold={fold}, w={w}\")\n",
    "        return\n",
    "\n",
    "    # Correlation computations\n",
    "    pearson_corr, pearson_p = pearsonr(results_df['delta'], results_df['accuracy'])\n",
    "    spearman_corr, spearman_p = spearmanr(results_df['delta'], results_df['accuracy'])\n",
    "\n",
    "    #¬†save the results_df with the 'delta' column to a CSV file\n",
    "    results_df.to_csv(f\"{dataset}/{dataset}_results/with_delta_classification_results_fold_{fold}_w{w}.csv\", index=False) \n",
    "        \n",
    "\n",
    "    #print(f\"üìä Pearson correlation: {pearson_corr:.4f} (p={pearson_p:.4e})\")\n",
    "    #print(f\"üìà Spearman correlation: {spearman_corr:.4f} (p={spearman_p:.4e})\")\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(results_df['delta'], results_df['accuracy'], alpha=0.7)\n",
    "\n",
    "    # Regression line\n",
    "    z = np.polyfit(results_df['delta'], results_df['accuracy'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_vals = np.sort(results_df['delta'])\n",
    "    plt.plot(x_vals, p(x_vals), \"r--\", label=f\"y={z[0]:.4f}x + {z[1]:.4f}\")\n",
    "\n",
    "    # Text annotation\n",
    "    plt.text(0.05, 0.05,\n",
    "             f\"Pearson r: {pearson_corr:.4f} (p={pearson_p:.4e})\\n\"\n",
    "             f\"Spearman r: {spearman_corr:.4f} (p={spearman_p:.4e})\",\n",
    "             transform=plt.gca().transAxes,\n",
    "             bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "    plt.xlabel(\"Delta Perplexity\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"Accuracy vs. Delta Perplexity ‚Äì Fold {fold}, Window {w}\")\n",
    "    plt.yticks(np.arange(0, 1.01, 0.05))\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot\n",
    "    plot_path = f\"fig/{dataset}/accuracy_vs_delta_fold_{fold}_w{w}.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    print(f\"‚úÖ Plot saved: {plot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_average_accuracy_not_overfitting_delta(epochs, folds, w, dataset):\n",
    "    list_of_accuracies = []\n",
    "    list_of_f1_ad = []\n",
    "    list_of_f1_cn = []\n",
    "    list_of_macro_f1 = []\n",
    "    for fold in folds:\n",
    "        try:\n",
    "            # Load results\n",
    "            results_df = pd.read_csv(f\"{dataset}/{dataset}_results/with_delta_classification_results_fold_{fold}_w{w}.csv\")\n",
    "\n",
    "            # Load matrix as NumPy array\n",
    "            matrix_df = pd.read_csv(f\"{dataset}/{dataset}_matrices/matrix_diff_ad_cn_fold_{fold}_w{w}.csv\", index_col=0)\n",
    "            matrix = matrix_df.values  # convert to NumPy array\n",
    "            \n",
    "            mean_ad_df = pd.read_csv(f\"{dataset}/{dataset}_matrices/mean_ad_fold_{fold}_w{w}.csv\", index_col=0)\n",
    "            mean_cn_df = pd.read_csv(f\"{dataset}/{dataset}_matrices/mean_cn_fold_{fold}_w{w}.csv\", index_col=0)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load data for fold {fold}, w {w}: {e}\")\n",
    "            return\n",
    "\n",
    "        min_ad_epoch_idx = mean_ad_df.values.argmin()\n",
    "        min_cn_epoch_idx = mean_cn_df.values.argmin()\n",
    "        min_ad_epoch_val = epochs[min_ad_epoch_idx]\n",
    "        min_cn_epoch_val = epochs[min_cn_epoch_idx]\n",
    "\n",
    "        # Filter using actual epoch values\n",
    "        results_df = results_df[\n",
    "            (results_df['ad_epoch'] <= min_ad_epoch_val) & (results_df['cn_epoch'] <= min_cn_epoch_val)\n",
    "        ]\n",
    "\n",
    "        results_df.dropna(subset=['accuracy'], inplace=True)\n",
    "\n",
    "        if len(results_df) < 2:\n",
    "            print(f\"‚ö†Ô∏è Not enough valid data to compute average accuracy for fold={fold}, w={w}\")\n",
    "            return\n",
    "\n",
    "        # take the configuration with the minumum lower bound\n",
    "        min_lower_bound = results_df['delta'].min()\n",
    "        best_config = results_df[results_df['delta'] == min_lower_bound].iloc[0]\n",
    "        average_accuracy = best_config['accuracy']\n",
    "        #print(f\"Fold {fold} - Best CN Epoch: {best_config['cn_epoch']}, Best AD Epoch: {best_config['ad_epoch']}, Accuracy: {average_accuracy:.4f}\")\n",
    "\n",
    "        f1_ad = best_config['f1_ad'] if 'f1_ad' in best_config else None\n",
    "        f1_cn = best_config['f1_cn'] if 'f1_cn' in best_config else None\n",
    "        macro_f1 = best_config['macro_f1'] if 'macro_f1' in best_config else None\n",
    "\n",
    "        #print(f\"AD predicted CN: {ad_predicted_cn}, CN predicted AD: {cn_predicted_ad}\")\n",
    "        #print(\"--------------------\")\n",
    "        \n",
    "        list_of_accuracies.append(average_accuracy)\n",
    "        list_of_f1_ad.append(f1_ad)\n",
    "        list_of_f1_cn.append(f1_cn)\n",
    "        list_of_macro_f1.append(macro_f1) \n",
    "    \n",
    "    # Calculate the average accuracy across all folds\n",
    "    if list_of_accuracies:\n",
    "        average_accuracy = np.mean(list_of_accuracies)\n",
    "        standard_deviation = np.std(list_of_accuracies)\n",
    "        average_f1_ad = np.mean([f for f in list_of_f1_ad if f is not None])\n",
    "        average_f1_cn = np.mean([f for f in list_of_f1_cn if f is not None])\n",
    "        average_macro_f1 = np.mean([f for f in list_of_macro_f1 if f is not None])\n",
    "        std_f1_macro_f1 = np.std([f for f in list_of_macro_f1 if f is not None])\n",
    "        print(f\"Average accuracy across folds - Dataset {dataset}: {average_accuracy:.4f} ¬± {standard_deviation:.4f}\")\n",
    "        print(f\"Average F1 AD across folds - Dataset {dataset}: {average_f1_ad:.4f}\")\n",
    "        print(f\"Average F1 CN across folds - Dataset {dataset}: {average_f1_cn:.4f}\")\n",
    "        print(f\"Average Macro F1 across folds - Dataset {dataset}: {average_macro_f1:.4f}, ¬± {std_f1_macro_f1:.4f}\")\n",
    "    else:\n",
    "        print(f\"No valid accuracies found for- Window {w} - Dataset {dataset}.\")\n",
    "    return list_of_accuracies         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_average_accuracy_not_overfitting_baseline(epochs, folds, w, dataset):\n",
    "    list_of_accuracies = []\n",
    "    list_of_f1_ad = []\n",
    "    list_of_f1_cn = []\n",
    "    list_of_macro_f1 = []\n",
    "    for fold in folds:\n",
    "        try:\n",
    "            # Load results\n",
    "            results_df = pd.read_csv(f\"{dataset}/{dataset}_results/classification_results_fold_{fold}_w{w}.csv\")\n",
    "\n",
    "            # Load matrices\n",
    "            mean_ad_df = pd.read_csv(f\"{dataset}/{dataset}_matrices/mean_ad_fold_{fold}_w{w}.csv\", index_col=0)\n",
    "            mean_cn_df = pd.read_csv(f\"{dataset}/{dataset}_matrices/mean_cn_fold_{fold}_w{w}.csv\", index_col=0)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load data for fold {fold}, w {w}: {e}\")\n",
    "            return\n",
    "\n",
    "        # Find epochs corresponding to minimum values\n",
    "        min_ad_epoch_idx = mean_ad_df.values.argmin()\n",
    "        min_cn_epoch_idx = mean_cn_df.values.argmin()\n",
    "        min_ad_epoch_val = epochs[min_ad_epoch_idx]\n",
    "        min_cn_epoch_val = epochs[min_cn_epoch_idx]\n",
    "\n",
    "        # Select the row that exactly matches both min_ad_epoch and min_cn_epoch\n",
    "        matching_row = results_df[\n",
    "            (results_df['ad_epoch'] == min_ad_epoch_val) & \n",
    "            (results_df['cn_epoch'] == min_cn_epoch_val)\n",
    "        ]\n",
    "\n",
    "        if matching_row.empty:\n",
    "            print(f\"‚ö†Ô∏è No matching configuration found for min_ad={min_ad_epoch_val}, min_cn={min_cn_epoch_val} in fold={fold}\")\n",
    "            continue\n",
    "\n",
    "        accuracy = matching_row.iloc[0]['accuracy']\n",
    "        list_of_accuracies.append(accuracy)\n",
    "        f1_ad = matching_row.iloc[0]['f1_ad'] if 'f1_ad' in matching_row.columns else None\n",
    "        f1_cn = matching_row.iloc[0]['f1_cn'] if 'f1_cn' in matching_row.columns else None\n",
    "        macro_f1 = matching_row.iloc[0]['macro_f1'] if 'macro_f1' in matching_row.columns else None\n",
    "        list_of_f1_ad.append(f1_ad)\n",
    "        list_of_f1_cn.append(f1_cn)\n",
    "        list_of_macro_f1.append(macro_f1)\n",
    "\n",
    "        #print(f\"Fold {fold} - Best CN Epoch: {matching_row.iloc[0]['cn_epoch']}, Best AD Epoch: {matching_row.iloc[0]['ad_epoch']},  Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "    # Compute and report overall average and standard deviation\n",
    "    if list_of_accuracies:\n",
    "        average_accuracy = np.mean(list_of_accuracies)\n",
    "        standard_deviation = np.std(list_of_accuracies)\n",
    "        average_f1_ad = np.mean([f for f in list_of_f1_ad if f is not None])\n",
    "        average_f1_cn = np.mean([f for f in list_of_f1_cn if f is not None])\n",
    "        average_macro_f1 = np.mean([f for f in list_of_macro_f1 if f is not None])\n",
    "        std_macro_f1 = np.std([f for f in list_of_macro_f1 if f is not None])\n",
    "        print(f\"Average accuracy across folds - Dataset {dataset}: {average_accuracy:.4f} ¬± {standard_deviation:.4f}\")\n",
    "        print(f\"Average F1 AD across folds - Dataset {dataset}: {average_f1_ad:.4f}\")\n",
    "        print(f\"Average F1 CN across folds - Dataset {dataset}: {average_f1_cn:.4f}\")\n",
    "        print(f\"Average Macro F1 across folds - Dataset {dataset}: {average_macro_f1:.4f}, ¬± {std_macro_f1:.4f}\")\n",
    "        return list_of_accuracies\n",
    "    else:\n",
    "        print(f\"No valid accuracies found for any fold in Window {w} - Dataset {dataset}.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_oracle_classification_without_overfitting(epochs, folds, w, dataset):\n",
    "    list_of_avg_accuracies = []\n",
    "    list_of_f1_ad = []\n",
    "    list_of_f1_cn = []\n",
    "    list_of_macro_f1 = []\n",
    "\n",
    "    for fold in folds:\n",
    "        try:\n",
    "            # Load results\n",
    "            results_df = pd.read_csv(f\"{dataset}/{dataset}_results/with_delta_classification_results_fold_{fold}_w{w}.csv\")\n",
    "\n",
    "            # Load matrices\n",
    "            mean_ad_df = pd.read_csv(f\"{dataset}/{dataset}_matrices/mean_ad_fold_{fold}_w{w}.csv\", index_col=0)\n",
    "            mean_cn_df = pd.read_csv(f\"{dataset}/{dataset}_matrices/mean_cn_fold_{fold}_w{w}.csv\", index_col=0)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load data for fold {fold}, w {w}: {e}\")\n",
    "            return\n",
    "\n",
    "        # Find epochs corresponding to minimum values\n",
    "        min_ad_epoch_idx = mean_ad_df.values.argmin()\n",
    "        min_cn_epoch_idx = mean_cn_df.values.argmin()\n",
    "        min_ad_epoch_val = epochs[min_ad_epoch_idx]\n",
    "        min_cn_epoch_val = epochs[min_cn_epoch_idx]\n",
    "        \n",
    "\n",
    "        # Filter only rows matching the no-overfitting condition\n",
    "        filtered_df = results_df[\n",
    "            (results_df['ad_epoch'] <= min_ad_epoch_val) &\n",
    "            (results_df['cn_epoch'] <= min_cn_epoch_val)\n",
    "        ]\n",
    "\n",
    "        if filtered_df.empty:\n",
    "            print(f\"‚ö†Ô∏è No matching configuration found for min_ad={min_ad_epoch_val}, min_cn={min_cn_epoch_val} in fold={fold}\")\n",
    "            continue\n",
    "\n",
    "        # Sort by accuracy and pick the top one\n",
    "        matching_row = filtered_df.sort_values(by='accuracy', ascending=False).head(1)\n",
    "        accuracy = matching_row.iloc[0]['accuracy']\n",
    "        f1_ad = matching_row.iloc[0]['f1_ad'] if 'f1_ad' in matching_row.columns else None\n",
    "        f1_cn = matching_row.iloc[0]['f1_cn'] if 'f1_cn' in matching_row.columns else None\n",
    "        macro_f1 = matching_row.iloc[0]['macro_f1'] if 'macro_f1' in matching_row.columns else None\n",
    "        \n",
    "        list_of_avg_accuracies.append(accuracy)\n",
    "        list_of_f1_ad.append(f1_ad)\n",
    "        list_of_f1_cn.append(f1_cn)\n",
    "        list_of_macro_f1.append(macro_f1)\n",
    "\n",
    "\n",
    "\n",
    "    if list_of_avg_accuracies:\n",
    "        average_accuracy = np.mean(list_of_avg_accuracies)\n",
    "        standard_deviation = np.std(list_of_avg_accuracies)\n",
    "        average_f1_ad = np.mean([f for f in list_of_f1_ad if f is not None])\n",
    "        average_f1_cn = np.mean([f for f in list_of_f1_cn if f is not None])\n",
    "        average_macro_f1 = np.mean([f for f in list_of_macro_f1 if f is not None])\n",
    "        std_f1_macro_f1 = np.std([f for f in list_of_macro_f1 if f is not None])\n",
    "        print(f\"Average accuracy across folds - Dataset {dataset}: {average_accuracy:.4f} ¬± {standard_deviation:.4f}\")\n",
    "        print(f\"Average F1 AD across folds - Dataset {dataset}: {average_f1_ad:.4f}\")\n",
    "        print(f\"Average F1 CN across folds - Dataset {dataset}: {average_f1_cn:.4f}\")\n",
    "        print(f\"Average Macro F1 across folds - Dataset {dataset}: {average_macro_f1:.4f}, ¬± {std_f1_macro_f1:.4f}\")\n",
    "        return list_of_avg_accuracies\n",
    "    else:\n",
    "        print(f\"No valid accuracies found for any fold in Window {w} - Dataset {dataset}.\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_global_perplexities_only_same_class(base_dir, group, epochs, subj_classes, transcription_type, batch_size):\n",
    "    patient_dirs = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "    patient_dirs.sort()\n",
    "    \n",
    "    dict_ppl = {e: [] for e in epochs}\n",
    "    \n",
    "    for patient_dir in patient_dirs:\n",
    "        if subj_classes[patient_dir] == group:\n",
    "            patient_path = os.path.join(base_dir, patient_dir)\n",
    "            for e in epochs:\n",
    "                file_name = f\"{patient_dir}_modello_{group}_{transcription_type}_{batch_size}b_{e}ep_global_ppl_score.txt\"\n",
    "                try:\n",
    "                    with open(os.path.join(patient_path, file_name), 'r') as f:\n",
    "                        perplexity = float(f.read().strip())\n",
    "                        dict_ppl[e].append(perplexity)\n",
    "                except FileNotFoundError:\n",
    "                    continue\n",
    "\n",
    "    return dict_ppl\n",
    "\n",
    "def load_global_perplexities_only_inverse_class(base_dir, group, epochs, subj_classes, transcription_type, batch_size):\n",
    "    patient_dirs = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "    patient_dirs.sort()\n",
    "    \n",
    "    dict_ppl = {e: [] for e in epochs}\n",
    "    \n",
    "    for patient_dir in patient_dirs:\n",
    "        if subj_classes[patient_dir] != group:\n",
    "            patient_path = os.path.join(base_dir, patient_dir)\n",
    "            for e in epochs:\n",
    "                file_name = f\"{patient_dir}_modello_{group}_{transcription_type}_{batch_size}b_{e}ep_global_ppl_score.txt\"\n",
    "                try:\n",
    "                    with open(os.path.join(patient_path, file_name), 'r') as f:\n",
    "                        perplexity = float(f.read().strip())\n",
    "                        dict_ppl[e].append(perplexity)\n",
    "                except FileNotFoundError:\n",
    "                    continue\n",
    "\n",
    "    return dict_ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_plot_global_same_class(w, epochs, fold, subj_classes, dataset, transcription_type, batch_size):\n",
    "\n",
    "    base_dir = f\"{dataset}/{dataset}_fold_{fold}/{dataset}_fold_{fold}_w{w}_l0/dev/{transcription_type}\"\n",
    "\n",
    "    dict_ad = load_global_perplexities_only_same_class(base_dir, \"ad\", epochs, subj_classes, transcription_type, batch_size)\n",
    "    dict_cn = load_global_perplexities_only_same_class(base_dir, \"cn\", epochs, subj_classes, transcription_type, batch_size)\n",
    "    \n",
    "    dict_ad_model_cn_subjects = load_global_perplexities_only_inverse_class(base_dir, \"ad\", epochs, subj_classes, transcription_type, batch_size)\n",
    "    dict_cn_model_ad_subjects = load_global_perplexities_only_inverse_class(base_dir, \"cn\", epochs, subj_classes, transcription_type, batch_size)\n",
    "\n",
    "    mean_ad = [np.nanmean(dict_ad[e]) for e in epochs]\n",
    "    mean_cn = [np.nanmean(dict_cn[e]) for e in epochs]\n",
    "    \n",
    "    mean_ad_model_cn_subjects = [np.nanmean(dict_ad_model_cn_subjects[e]) for e in epochs]\n",
    "    mean_cn_model_ad_subjects = [np.nanmean(dict_cn_model_ad_subjects[e]) for e in epochs]\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    #plt.plot(epochs, mean_ad, marker='o', label='AD Model on AD Subjects', color='red', markersize=3)\n",
    "    #plt.plot(epochs, mean_cn, marker='o', label='HC Model on HC Subjects', color='blue', markersize=3)\n",
    "    #plt.plot(epochs, mean_ad_model_cn_subjects, marker='o', label='AD Model on HC Subjects', color='red', markersize=3, linestyle='--')\n",
    "    #plt.plot(epochs, mean_cn_model_ad_subjects, marker='o', label='HC Model on AD Subjects', color='blue', markersize=3, linestyle='--')\n",
    "    \n",
    "    plt.plot(epochs, mean_ad, marker='o', color='red', markersize=4)\n",
    "    plt.plot(epochs, mean_cn, marker='o', color='blue', markersize=4)\n",
    "    \n",
    "    # # i want to highlight the points 2 for mean_cn_model_ad_subjects and mean_cn and 5 for the other two\n",
    "    # plt.scatter(2, mean_cn_model_ad_subjects[1], color='none', s=50, zorder=3, marker='o')\n",
    "    #plt.scatter(2, mean_cn[1], color='blue', s=100, zorder=3, marker='D')\n",
    "    # plt.scatter(5, mean_ad_model_cn_subjects[4], color='none', s=70, zorder=3, marker='o')\n",
    "    #plt.scatter(5, mean_ad[4], color='red', s=100, zorder=3, marker='s')\n",
    "\n",
    "    # Highlight points (hollow markers)\n",
    "    # plt.scatter(2, mean_cn_model_ad_subjects[1], facecolors='none', edgecolors='blue',\n",
    "    #             s=200, zorder=3, marker='o', linewidths=1.5)\n",
    "    # plt.scatter(5, mean_ad_model_cn_subjects[4], facecolors='none', edgecolors='red',\n",
    "    #             s=200, zorder=3, marker='o', linewidths=1.5)\n",
    "            \n",
    "    \n",
    "    #plt.xlabel('Epoch')\n",
    "    #plt.ylabel('Perplexity')\n",
    "    #plt.title(f'Global Perplexity Evolution - Dev. Set - Fold {fold} - Window {w}')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    #plt.xticks(ticks=[2, 4, 6, 8, 10, 12])  # ensures all epoch numbers are displayed\n",
    "    #plt.xlim(min(epochs), max(epochs))  # adjust automatically if epochs ‚â† 1‚Äì15\n",
    "    plt.xticks(ticks=[5,10,15], fontsize=20) \n",
    "    plt.yticks(fontsize=20)\n",
    "    \n",
    "    plt.ylim(10,70)\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "    # for means, color in zip([mean_ad, mean_cn], ['red', 'blue']):\n",
    "    #     for x, y in zip(epochs, means):\n",
    "    #         plt.text(x, y + 0.02, f\"{y:.2f}\", ha='center', color=color)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_name = f\"fig/{dataset}/same_class_perplexity_evolution_dev_set_fold_{fold}_w{w}\"\n",
    "    plt.savefig(f\"{plot_name}.png\")\n",
    "    \n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Matrice differenze (AD - CN)\n",
    "    matrix = np.empty((len(epochs), len(epochs)))\n",
    "    for i, ad_epoch in enumerate(epochs):\n",
    "        for j, cn_epoch in enumerate(epochs):\n",
    "            ad_vals = dict_ad[ad_epoch]\n",
    "            cn_vals = dict_cn[cn_epoch]\n",
    "            if ad_vals and cn_vals:  # check that both lists are not empty\n",
    "                matrix[i, j] = np.mean(ad_vals) - np.mean(cn_vals)\n",
    "            else:\n",
    "                matrix[i, j] = np.nan\n",
    "    \n",
    "    #¬†Save the matrix to a CSV file\n",
    "    matrix_df = pd.DataFrame(matrix, index=epochs, columns=epochs)\n",
    "    matrix_df.to_csv(f\"{dataset}/{dataset}_matrices/same_class_matrix_diff_ad_cn_fold_{fold}_w{w}.csv\", index=True, header=True)\n",
    "\n",
    "    mean_ad_df = pd.DataFrame(mean_ad, index=epochs, columns=['Mean AD'])\n",
    "    mean_ad_df.to_csv(f\"{dataset}/{dataset}_matrices/same_class_mean_ad_fold_{fold}_w{w}.csv\", index=True, header=True)\n",
    "    mean_cn_df = pd.DataFrame(mean_cn, index=epochs, columns=['Mean CN'])\n",
    "    mean_cn_df.to_csv(f\"{dataset}/{dataset}_matrices/same_class_mean_cn_fold_{fold}_w{w}.csv\", index=True, header=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_correlation_ppl_valid_classific_test_same_class(epochs, fold, w, dataset):\n",
    "    try:\n",
    "        # Load results\n",
    "        results_df = pd.read_csv(f\"{dataset}/{dataset}_results/classification_results_fold_{fold}_w{w}.csv\")\n",
    "\n",
    "        # Load matrix as NumPy array\n",
    "        matrix_df = pd.read_csv(f\"{dataset}/{dataset}_matrices/same_class_matrix_diff_ad_cn_fold_{fold}_w{w}.csv\", index_col=0)\n",
    "        matrix = matrix_df.values  # convert to NumPy array\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load data for fold {fold}, w {w}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Compute deltas using index lookup\n",
    "    deltas = []\n",
    "    for _, row in results_df.iterrows():\n",
    "        try:\n",
    "            i = epochs.index(row['ad_epoch'])\n",
    "            j = epochs.index(row['cn_epoch'])\n",
    "            deltas.append(abs(matrix[i, j]))\n",
    "        except Exception:\n",
    "            deltas.append(np.nan)\n",
    "\n",
    "    results_df['delta'] = deltas\n",
    "    results_df.dropna(subset=['accuracy', 'delta'], inplace=True)\n",
    "\n",
    "    if len(results_df) < 2:\n",
    "        print(f\"‚ö†Ô∏è Not enough valid data to compute correlation for fold={fold}, w={w}\")\n",
    "        return\n",
    "\n",
    "    # Correlation computations\n",
    "    pearson_corr, pearson_p = pearsonr(results_df['delta'], results_df['accuracy'])\n",
    "    spearman_corr, spearman_p = spearmanr(results_df['delta'], results_df['accuracy'])\n",
    "    \n",
    "    results_df.to_csv(f\"{dataset}/{dataset}_results/same_class_with_delta_classification_results_fold_{fold}_w{w}.csv\", index=False) \n",
    "\n",
    "\n",
    "    #print(f\"üìä Pearson correlation: {pearson_corr:.4f} (p={pearson_p:.4e})\")\n",
    "    #print(f\"üìà Spearman correlation: {spearman_corr:.4f} (p={spearman_p:.4e})\")\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(results_df['delta'], results_df['accuracy'], alpha=0.7)\n",
    "    \n",
    "\n",
    "    # Regression line\n",
    "    z = np.polyfit(results_df['delta'], results_df['accuracy'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_vals = np.sort(results_df['delta'])\n",
    "    plt.plot(x_vals, p(x_vals), \"r--\", label=f\"y={z[0]:.4f}x + {z[1]:.4f}\")\n",
    "\n",
    "    # Text annotation\n",
    "    plt.text(0.05, 0.05,\n",
    "             f\"Pearson r: {pearson_corr:.4f} (p={pearson_p:.4e})\\n\"\n",
    "             f\"Spearman r: {spearman_corr:.4f} (p={spearman_p:.4e})\",\n",
    "             transform=plt.gca().transAxes,\n",
    "             bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "    plt.xlabel(\"Delta Perplexity\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"Accuracy vs. Delta Perplexity ‚Äì Fold {fold}, Window {w}\")\n",
    "    plt.yticks(np.arange(0, 1.01, 0.05))\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot\n",
    "    plot_path = f\"fig/{dataset}/same_class_accuracy_vs_delta_fold_{fold}_w{w}.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    print(f\"‚úÖ Plot saved: {plot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_correlation_ppl_valid_classific_test_not_overfitting_same_class(epochs, fold, w, dataset):\n",
    "    try:\n",
    "        # Load results\n",
    "        results_df = pd.read_csv(f\"{dataset}/{dataset}_results/classification_results_fold_{fold}_w{w}.csv\")\n",
    "\n",
    "        # Load matrix as NumPy array\n",
    "        matrix_df = pd.read_csv(f\"{dataset}/{dataset}_matrices/same_class_matrix_diff_ad_cn_fold_{fold}_w{w}.csv\", index_col=0)\n",
    "        matrix = matrix_df.values  # convert to NumPy array\n",
    "        \n",
    "        mean_ad_df = pd.read_csv(f\"{dataset}/{dataset}_matrices/same_class_mean_ad_fold_{fold}_w{w}.csv\", index_col=0)\n",
    "        mean_cn_df = pd.read_csv(f\"{dataset}/{dataset}_matrices/same_class_mean_cn_fold_{fold}_w{w}.csv\", index_col=0)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load data for fold {fold}, w {w}: {e}\")\n",
    "        return\n",
    "\n",
    "    min_ad_epoch_idx = mean_ad_df.values.argmin()\n",
    "    min_cn_epoch_idx = mean_cn_df.values.argmin()\n",
    "    min_ad_epoch_val = epochs[min_ad_epoch_idx]\n",
    "    min_cn_epoch_val = epochs[min_cn_epoch_idx]\n",
    "\n",
    "    #print(f\"Minimum AD perplexity at epoch: {min_ad_epoch_val} with value {mean_ad_df.values[min_ad_epoch_idx][0]:.2f}\")\n",
    "\n",
    "    # Filter using actual epoch values\n",
    "    results_df = results_df[\n",
    "        (results_df['ad_epoch'] <= min_ad_epoch_val) & (results_df['cn_epoch'] <= min_cn_epoch_val)\n",
    "    ]\n",
    "\n",
    "    \n",
    "    #print(results_df)\n",
    "\n",
    "    # Compute error bounds *after* filtering\n",
    "    deltas = []\n",
    "    for _, row in results_df.iterrows():\n",
    "        try:\n",
    "            i = epochs.index(row['ad_epoch'])\n",
    "            j = epochs.index(row['cn_epoch'])\n",
    "            deltas.append(abs(matrix[i, j]))\n",
    "        except Exception:\n",
    "            deltas.append(np.nan)\n",
    "\n",
    "    results_df['delta'] = deltas\n",
    "    results_df.dropna(subset=['accuracy', 'delta'], inplace=True)\n",
    "\n",
    "    if len(results_df) < 2:\n",
    "        print(f\"‚ö†Ô∏è Not enough valid data to compute correlation for fold={fold}, w={w}\")\n",
    "        return\n",
    "\n",
    "    # Correlation computations\n",
    "    pearson_corr, pearson_p = pearsonr(results_df['delta'], results_df['accuracy'])\n",
    "    spearman_corr, spearman_p = spearmanr(results_df['delta'], results_df['accuracy'])\n",
    "\n",
    "        \n",
    "    #print(f\"üìä Pearson correlation: {pearson_corr:.4f} (p={pearson_p:.4e})\")\n",
    "    #print(f\"üìà Spearman correlation: {spearman_corr:.4f} (p={spearman_p:.4e})\")\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(results_df['delta'], results_df['accuracy'], alpha=0.7)\n",
    "\n",
    "    # Regression line\n",
    "    z = np.polyfit(results_df['delta'], results_df['accuracy'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_vals = np.sort(results_df['delta'])\n",
    "    plt.plot(x_vals, p(x_vals), \"r--\", label=f\"y={z[0]:.4f}x + {z[1]:.4f}\")\n",
    "\n",
    "    # Text annotation\n",
    "    plt.text(0.05, 0.05,\n",
    "             f\"Pearson r: {pearson_corr:.4f} (p={pearson_p:.4e})\\n\"\n",
    "             f\"Spearman r: {spearman_corr:.4f} (p={spearman_p:.4e})\",\n",
    "             transform=plt.gca().transAxes,\n",
    "             bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "    plt.xlabel(\"Delta Perplexity\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"Accuracy vs. Delta Perplexity ‚Äì Fold {fold}, Window {w}\")\n",
    "    plt.yticks(np.arange(0, 1.01, 0.05))\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot\n",
    "    plot_path = f\"fig/{dataset}/same_class_not_overfitting_accuracy_vs_delta_fold_{fold}_w{w}.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    print(f\"‚úÖ Plot saved: {plot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_average_accuracy_not_overfitting_baseline_same_class(epochs, folds, w, dataset):\n",
    "    list_of_accuracies = []\n",
    "    list_of_f1_ad = []\n",
    "    list_of_f1_cn = []\n",
    "    list_of_macro_f1 = []\n",
    "\n",
    "    for fold in folds:\n",
    "        try:\n",
    "            # Load results\n",
    "            results_df = pd.read_csv(f\"{dataset}/{dataset}_results/same_class_with_delta_classification_results_fold_{fold}_w{w}.csv\")\n",
    "\n",
    "            # Load matrices\n",
    "            mean_ad_df = pd.read_csv(f\"{dataset}/{dataset}_matrices/same_class_mean_ad_fold_{fold}_w{w}.csv\", index_col=0)\n",
    "            mean_cn_df = pd.read_csv(f\"{dataset}/{dataset}_matrices/same_class_mean_cn_fold_{fold}_w{w}.csv\", index_col=0)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load data for fold {fold}, w {w}: {e}\")\n",
    "            return\n",
    "\n",
    "        # Find epochs corresponding to minimum values\n",
    "        min_ad_epoch_idx = mean_ad_df.values.argmin()\n",
    "        min_cn_epoch_idx = mean_cn_df.values.argmin()\n",
    "        min_ad_epoch_val = epochs[min_ad_epoch_idx]\n",
    "        min_cn_epoch_val = epochs[min_cn_epoch_idx]\n",
    "\n",
    "        # Select the row that exactly matches both min_ad_epoch and min_cn_epoch\n",
    "        matching_row = results_df[\n",
    "            (results_df['ad_epoch'] == min_ad_epoch_val) & \n",
    "            (results_df['cn_epoch'] == min_cn_epoch_val)\n",
    "        ]\n",
    "\n",
    "        if matching_row.empty:\n",
    "            print(f\"‚ö†Ô∏è No matching configuration found for min_ad={min_ad_epoch_val}, min_cn={min_cn_epoch_val} in fold={fold}\")\n",
    "            continue\n",
    "\n",
    "        accuracy = matching_row.iloc[0]['accuracy']\n",
    "        list_of_accuracies.append(accuracy)\n",
    "        f1_ad = matching_row.iloc[0]['f1_ad'] if 'f1_ad' in matching_row.columns else None\n",
    "        f1_cn = matching_row.iloc[0]['f1_cn'] if 'f1_cn' in matching_row.columns else None\n",
    "        macro_f1 = matching_row.iloc[0]['macro_f1'] if 'macro_f1' in matching_row.columns else None\n",
    "        list_of_f1_ad.append(f1_ad)\n",
    "        list_of_f1_cn.append(f1_cn)\n",
    "        list_of_macro_f1.append(macro_f1)\n",
    "\n",
    "    # Compute and report overall average and standard deviation\n",
    "    if list_of_accuracies:\n",
    "        average_accuracy = np.mean(list_of_accuracies)\n",
    "        standard_deviation = np.std(list_of_accuracies)\n",
    "        average_f1_ad = np.mean([f for f in list_of_f1_ad if f is not None])\n",
    "        average_f1_cn = np.mean([f for f in list_of_f1_cn if f is not None])\n",
    "        average_macro_f1 = np.mean([f for f in list_of_macro_f1 if f is not None])\n",
    "        std_macro_f1 = np.std([f for f in list_of_macro_f1 if f is not None])\n",
    "        print(f\"Average accuracy across folds for dataset {dataset}: {average_accuracy:.4f} ¬± {standard_deviation:.4f}\")\n",
    "        print(f\"Average F1 AD across folds - Dataset {dataset}: {average_f1_ad:.4f}\")\n",
    "        print(f\"Average F1 CN across folds - Dataset {dataset}: {average_f1_cn:.4f}\")\n",
    "        print(f\"Average Macro F1 across folds - Dataset {dataset}: {average_macro_f1:.4f}, ¬± {std_macro_f1:.4f}\")\n",
    "        return average_accuracy\n",
    "    else:\n",
    "        print(f\"No valid accuracies found for any fold in Window {w} - Dataset {dataset}.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_average_accuracy_not_overfitting_delta_same_class(epochs, folds, w, dataset):\n",
    "    list_of_accuracies = []\n",
    "    list_of_f1_ad = []\n",
    "    list_of_f1_cn = []\n",
    "    list_of_macro_f1 = []\n",
    "\n",
    "    for fold in folds:\n",
    "        try:\n",
    "            # Load results\n",
    "            results_df = pd.read_csv(f\"{dataset}/{dataset}_results/same_class_with_delta_classification_results_fold_{fold}_w{w}.csv\")\n",
    "\n",
    "            # Load matrix as NumPy array\n",
    "            matrix_df = pd.read_csv(f\"{dataset}/{dataset}_matrices/same_class_matrix_diff_ad_cn_fold_{fold}_w{w}.csv\", index_col=0)\n",
    "            matrix = matrix_df.values  # convert to NumPy array\n",
    "            \n",
    "            mean_ad_df = pd.read_csv(f\"{dataset}/{dataset}_matrices/same_class_mean_ad_fold_{fold}_w{w}.csv\", index_col=0)\n",
    "            mean_cn_df = pd.read_csv(f\"{dataset}/{dataset}_matrices/same_class_mean_cn_fold_{fold}_w{w}.csv\", index_col=0)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load data for fold {fold}, w {w}: {e}\")\n",
    "            return\n",
    "\n",
    "        min_ad_epoch_idx = mean_ad_df.values.argmin()\n",
    "        min_cn_epoch_idx = mean_cn_df.values.argmin()\n",
    "        min_ad_epoch_val = epochs[min_ad_epoch_idx]\n",
    "        min_cn_epoch_val = epochs[min_cn_epoch_idx]\n",
    "\n",
    "        # Filter using actual epoch values\n",
    "        results_df = results_df[\n",
    "            (results_df['ad_epoch'] <= min_ad_epoch_val) & (results_df['cn_epoch'] <= min_cn_epoch_val)\n",
    "        ]\n",
    "\n",
    "        results_df.dropna(subset=['accuracy'], inplace=True)\n",
    "\n",
    "        if len(results_df) < 2:\n",
    "            print(f\"‚ö†Ô∏è Not enough valid data to compute average accuracy for fold={fold}, w={w}\")\n",
    "            return\n",
    "\n",
    "        # take the configuration with the minumum lower bound\n",
    "        min_lower_bound = results_df['delta'].min()\n",
    "        best_config = results_df[results_df['delta'] == min_lower_bound].iloc[0]\n",
    "        average_accuracy = best_config['accuracy']\n",
    "        list_of_accuracies.append(average_accuracy)\n",
    "        f1_ad = best_config['f1_ad'] if 'f1_ad' in best_config else None\n",
    "        f1_cn = best_config['f1_cn'] if 'f1_cn' in best_config else None\n",
    "        macro_f1 = best_config['macro_f1'] if 'macro_f1' in best_config else None\n",
    "        list_of_f1_ad.append(f1_ad)\n",
    "        list_of_f1_cn.append(f1_cn)\n",
    "        list_of_macro_f1.append(macro_f1)\n",
    "        \n",
    "    # Calculate the average accuracy across all folds\n",
    "    if list_of_accuracies:\n",
    "        average_accuracy = np.mean(list_of_accuracies)\n",
    "        standard_deviation = np.std(list_of_accuracies)\n",
    "        average_f1_ad = np.mean([f for f in list_of_f1_ad if f is not None])\n",
    "        average_f1_cn = np.mean([f for f in list_of_f1_cn if f is not None])\n",
    "        average_macro_f1 = np.mean([f for f in list_of_macro_f1 if f is not None])\n",
    "        std_macro_f1 = np.std([f for f in list_of_macro_f1 if f is not None])\n",
    "        print(f\"Average accuracy across folds for dataset {dataset}: {average_accuracy:.4f} ¬± {standard_deviation:.4f}\")\n",
    "        print(f\"Average F1 AD across folds - Dataset {dataset}: {average_f1_ad:.4f}\")\n",
    "        print(f\"Average F1 CN across folds - Dataset {dataset}: {average_f1_cn:.4f}\")\n",
    "        print(f\"Average Macro F1 across folds - Dataset {dataset}: {average_macro_f1:.4f}, ¬± {std_macro_f1:.4f}\")\n",
    "    else:\n",
    "        print(f\"No valid accuracies found for- Window {w} - Dataset {dataset}.\")\n",
    "    return average_accuracy         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main both classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The possible datasets are:\n",
    "- adress\n",
    "- adresso\n",
    "- adress_imb_60\n",
    "- adresso_imb_60\n",
    "- adress_imb_40\n",
    "- adresso_imb_40\n",
    "- adress_imb_20\n",
    "- adresso_imb_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [2]\n",
    "batch_size = 12\n",
    "w = 20\n",
    "epochs = list(range(1, 16, 1))\n",
    "disease_class = 'ad'  \n",
    "control_class = 'cn'\n",
    "\n",
    "list_datasets = [\"adress\", \"adresso\", \"adress_imb_60\", \"adresso_imb_60\", \"adress_imb_40\", \"adresso_imb_40\", \"adress_imb_20\", \"adresso_imb_20\"]\n",
    "\n",
    "list_datasets = [\"adress\", \"adress_imb_60\", \"adress_imb_40\", \"adress_imb_20\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in list_datasets:\n",
    "    transcription_type = \"manual\" if dataset.split(\"_\")[0] == \"adress\" else \"whisper-large-v3-turbo\"\n",
    "\n",
    "    subj_classes = {}\n",
    "    \n",
    "    for fold in folds:\n",
    "        print(f\"\\n=== Processing Fold {fold} ===\")\n",
    "\n",
    "        subj_classes[fold] = pd.read_csv(f\"{dataset}/labels_fold_{fold}.csv\", sep=';')\n",
    "        # make it a dictionary with patient_id as key and label as value\n",
    "        subj_classes[fold] = dict(zip(subj_classes[fold]['patient_id'], subj_classes[fold]['label']))\n",
    "\n",
    "        try:\n",
    "            process_and_plot_global(w=w, epochs=epochs, fold=fold, dataset=dataset, transcription_type=transcription_type, batch_size=batch_size, disease_class=disease_class, control_class=control_class)\n",
    "            process_and_plot_global_same_class(w=w, epochs=epochs, fold=fold, subj_classes = subj_classes[fold], dataset=dataset, transcription_type=transcription_type, batch_size=batch_size)\n",
    "\n",
    "            print(f\"‚úÖ Global perplexity processing completed for fold {fold}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error during dev processing (fold={fold}: {e}\")\n",
    "            continue\n",
    "        \n",
    "\n",
    "        # Step 2: Test classification\n",
    "        try:\n",
    "            base_dir_test = f\"{dataset}/{dataset}_fold_{fold}/{dataset}_fold_{fold}_w{w}_l0/test/{transcription_type}\"\n",
    "            classification_test(base_dir_test, epochs, fold, w, dataset, transcription_type, batch_size, disease_class, control_class)\n",
    "            print(f\"‚úÖ Classification test completed for fold {fold}, window {w}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error during classification (fold={fold}, w={w}): {e}\")\n",
    "            continue\n",
    "        \n",
    "        #¬†Step 3: Correlation analysis\n",
    "        try:\n",
    "            print_correlation_ppl_valid_classific_test(epochs, fold, w, dataset)\n",
    "            print_correlation_ppl_valid_classific_test_not_overfitting(epochs, fold, w, dataset)\n",
    "            print_correlation_ppl_valid_classific_test_same_class(epochs, fold, w, dataset)\n",
    "            print_correlation_ppl_valid_classific_test_not_overfitting_same_class(epochs, fold, w, dataset)\n",
    "            print(f\"‚úÖ Correlation analysis completed for fold {fold}, window {w}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error during correlation analysis not overfitting (fold={fold}, w={w}): {e}\") \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in list_datasets:\n",
    "    print(f\"\\n\\n================== FINAL RESULTS DATASET {dataset} ==================\")\n",
    "    print(f\"BASELINE SC: Using the pair composed by min_AD and min_CN perplexity for each fold:\")\n",
    "    average_accuracy_min_ad_min_cn = print_average_accuracy_not_overfitting_baseline_same_class(epochs, folds, w, dataset)   \n",
    "    print(\"***************************************************************************************\")\n",
    "     \n",
    "    print(f\"BASELINE BC:\")\n",
    "    average_accuracy_min_ad_min_cn = print_average_accuracy_not_overfitting_baseline(epochs, folds, w, dataset)   \n",
    "    print(\"***************************************************************************************\")\n",
    "    \n",
    "    print(f\"DELTA SC:\")\n",
    "    average_accuracy = print_average_accuracy_not_overfitting_delta_same_class(epochs, folds, w, dataset)\n",
    "    print(\"***************************************************************************************\")\n",
    "    \n",
    " \n",
    "    print(f\"DELTA BC:\")\n",
    "    average_accuracy = print_average_accuracy_not_overfitting_delta(epochs, folds, w, dataset)\n",
    "    print(\"***************************************************************************************\")\n",
    "    \n",
    "    print(f\"ORACLE:\")\n",
    "    average_accuracy_top = print_oracle_classification_without_overfitting(epochs, folds, w, dataset)\n",
    "    print(f\"---------------------------------------------------------------------------\")\n",
    "    print(f\"---------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delta_recalibration_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
